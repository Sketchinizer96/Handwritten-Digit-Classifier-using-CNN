import pandas as pd
import re
import spacy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.externals import joblib  # For saving the model

# Load SpaCy model for English
nlp = spacy.load("en_core_web_sm")

def load_data(file_path):
    return pd.read_excel(file_path)

def clean_text(text):
    # Remove non-alphabetic characters
    text = re.sub('[^a-zA-Z]', ' ', str(text))
    
    # Lemmatization and spell correction using SpaCy
    doc = nlp(text)
    lemmatized_text = ' '.join([token.lemma_ for token in doc])
    
    # Remove specific words
    custom_stopwords = ['word1', 'word2', 'etc.']  # Add your list of words to remove
    lemmatized_text = ' '.join([word for word in lemmatized_text.split() if word not in custom_stopwords])
    
    return lemmatized_text

def process_data(df):
    df['clean_description'] = df['description'].apply(clean_text)
    df['clean_close_notes'] = df['close_notes'].apply(clean_text)
    df['combined_text'] = df['clean_description'] + ' ' + df['clean_close_notes']
    return df[['combined_text', 'configuration_item']], df['ticket_tags']

def train_model(X_train, y_train):
    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
    X_train = vectorizer.fit_transform(X_train).toarray()

    mlb = MultiLabelBinarizer()
    y_train = mlb.fit_transform(y_train.apply(lambda x: str(x).split(',')))

    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    return model, vectorizer, mlb, X_test, y_test

def evaluate_and_save(model, vectorizer, mlb, X_test, model_save_path):
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, target_names=mlb.classes_)

    print(f'Accuracy: {accuracy}')
    print('Classification Report:')
    print(report)

    joblib.dump(model, f'{model_save_path}/model.joblib')
    print(f'Model saved at: {model_save_path}/model.joblib')

def main():
    file_path = 'your_data.xlsx'
    model_save_path = input("Enter the path to save the model: ")

    df = load_data(file_path)
    X, y = process_data(df)
    model, vectorizer, mlb, X_test, y_test = train_model(X['combined_text'], y)
    evaluate_and_save(model, vectorizer, mlb, X_test, model_save_path)

if __name__ == "__main__":
    main()
